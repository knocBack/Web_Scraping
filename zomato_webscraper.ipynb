{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a03f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using snake casing to name variables and functions\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd40334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "city_name = \"hyderabad\"\n",
    "zomato_url = \"https://www.zomato.com\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3e7b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(link,headers):\n",
    "    try:\n",
    "        #link = 'https://www.zomato.com/hyderabad/antera-kitchen-and-bar-jubilee-hills'\n",
    "        response = requests.get(link, headers=headers)\n",
    "        #response = requests.get(\"https://www.zomato.com/hyderabad/papadams-blue-kothapet/order\")\n",
    "        return {'status':response.status_code,\n",
    "                'content': response.content}\n",
    "    \n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"Http Error:\"+errh}\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"Error Connecting:\"+errc}\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"Timeout Error:\"+errt}\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"OOps: Something Else\"+err}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9fdfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_links_via_html(html):\n",
    "    try:\n",
    "        if(html):\n",
    "            soup = BeautifulSoup(html,\"lxml\")\n",
    "            search_list = soup.find_all(\"div\", {\"class\":\"jumbo-tracker\"})\n",
    "#             print(\"number of search_list:\"+str(len(search_list)))\n",
    "\n",
    "            restaurant_links=[]\n",
    "            ################################ \n",
    "            #need to edit here, indices starts from 22 to len() ??? we need all!\n",
    "            ################################ \n",
    "            for i in range(22,len(search_list)):\n",
    "                link = search_list[i].div.find('a')['href']\n",
    "                link = link.replace('/order', '')\n",
    "#                 print(link)\n",
    "                restaurant_links.append(zomato_url+link)\n",
    "\n",
    "#             print(\"total number of restaurant links:\" + str(len(restaurant_links)))\n",
    "            \n",
    "            #     for x in (details[0].find_all(True)):\n",
    "            #         if(x.string!=None):\n",
    "            #             print(x.string+' {}'.format(i))\n",
    "            #             i+=1\n",
    "            e = {\n",
    "                'status':200,\n",
    "                'content':restaurant_links\n",
    "            }\n",
    "#             print(e)\n",
    "            return e\n",
    "    except Exception as e:\n",
    "        e = {\"status\":999,'error':str(e)}\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# print(get_restaurant_links(city_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e9e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_links_via_href(city_name):\n",
    "    try:\n",
    "        url = \"https://www.zomato.com/{}/restaurants\".format(city_name)\n",
    "#         print(url)\n",
    "        response = get_page_content(url,headers)\n",
    "#         print(type(response))\n",
    "        if(response['status']==200):\n",
    "            content = response['content']\n",
    "            soup = BeautifulSoup(content,\"lxml\")\n",
    "            search_list = soup.find_all(\"div\", {\"class\":\"jumbo-tracker\"})\n",
    "#             print(\"number of search_list:\"+str(len(search_list)))\n",
    "\n",
    "            restaurant_links=[]\n",
    "            ################################ \n",
    "            #need to edit here, indices starts from 22 to len() ??? we need all!\n",
    "            ################################ \n",
    "            for i in range(22,len(search_list)):\n",
    "                link = search_list[i].div.find('a')['href']\n",
    "                link = link.replace('/order', '')\n",
    "#                 print(link)\n",
    "                restaurant_links.append(zomato_url+link)\n",
    "\n",
    "#             print(\"total number of restaurant links:\" + str(len(restaurant_links)))\n",
    "            \n",
    "            #     for x in (details[0].find_all(True)):\n",
    "            #         if(x.string!=None):\n",
    "            #             print(x.string+' {}'.format(i))\n",
    "            #             i+=1\n",
    "            status = {\n",
    "                'status':200,\n",
    "                'content':restaurant_links\n",
    "            }\n",
    "#             print(e)\n",
    "            return status\n",
    "    except Exception as e:\n",
    "        e = {\"status\":999,'error':str(e)}\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# print(get_restaurant_links(city_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b2094cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #just learnt abt beautiful-soup-4!\n",
    "\n",
    "# jumbo_tracker = soup.select('.jumbo-tracker')\n",
    "# tag = jumbo_tracker[0]\n",
    "# #print tag-name\n",
    "# print(tag.name) # yes its a div tag!\n",
    "# #u can edit tag name in the current soup too!\n",
    "# print(tag.attrs)\n",
    "# print(tag.get('class'))\n",
    "# print(type(soup))\n",
    "# print(len(soup.find_all(attrs={'class':'jumbo-tracker'})))\n",
    "# print(len(soup.find_all('div',attrs={'class':'jumbo-tracker'})))\n",
    "# print(len(soup.select('div[class=\"jumbo-tracker\"]')))\n",
    "# print(soup.select('div[class=\"jumbo-tracker\"]')[-1])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad1db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86d0a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns get restaurant page content for 200 successful response\n",
    "\n",
    "def get_primary_data(content):\n",
    "    try:\n",
    "        \n",
    "        soup = BeautifulSoup(content,\"lxml\")\n",
    "\n",
    "        main = soup.find(\"main\").div\n",
    "\n",
    "        # location = soup.find(\"div\",{\"aria-label\":\"Breadcrumb\"}).find_all(\"a\")\n",
    "        location = main.section.div.find_all(\"a\")\n",
    "#         print(location)\n",
    "\n",
    "        loc_tags = [tag[\"title\"] for tag in location]\n",
    "        \n",
    "        rest_all_tags = {'country':'','city':'','city_2':'','region':'','restaurant_name':''}\n",
    "        if(len(loc_tags)>=1):rest_all_tags [\"country\"] = loc_tags[1]\n",
    "        if(len(loc_tags)>=2):rest_all_tags [\"city\"] = loc_tags[2]\n",
    "        if(len(loc_tags)>=3):rest_all_tags [\"city_2\"] = loc_tags[3]\n",
    "        if(len(loc_tags)>=4):rest_all_tags [\"region\"] = loc_tags[4]\n",
    "        if(len(loc_tags)>=5):rest_all_tags [\"restaurant_name\"] = loc_tags[5]\n",
    "#         print(len(loc_tags))\n",
    "#         print(loc_tags)\n",
    "    #rest_all_tags[\"order_online\"] = True if(loc_tags[6]=='Order Online') else False\n",
    "    # order_online is invalid in off timings\n",
    "\n",
    "    # loc_tags = loc_tags[1:len(loc_tags)-1]\n",
    "\n",
    "#         print(rest_all_tags)\n",
    "        \n",
    "        e = {\n",
    "            'status': 200,\n",
    "            'content': rest_all_tags\n",
    "        }\n",
    "#         print(e)\n",
    "        return e\n",
    "    \n",
    "    except Exception as e:\n",
    "        e =  {\n",
    "            'status': 998,\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ab0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondary_data(content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(content,\"lxml\")\n",
    "        main = soup.find(\"main\").div\n",
    "\n",
    "        stuff = main.section.next_sibling.next_sibling.section\n",
    "        stuff = stuff.get_text(\"!@#$%^&\",strip=True).split(\"!@#$%^&\")\n",
    "    #         print(stuff)\n",
    "\n",
    "        rest_all_tags={'restaurant_name_2':'','dining_rating':0.0,'dining_reviews':0,'delivery_rating':0.0,'delivery_reviews':0,'cuisines':[],'location':''}\n",
    "        if(len(stuff)>=0):rest_all_tags[\"restaurant_name_2\"] = stuff[0]\n",
    "        if(len(stuff)>=1):rest_all_tags[\"dining_rating\"] = stuff[1]\n",
    "        if(len(stuff)>=3):rest_all_tags[\"dining_reviews\"] = stuff[3]\n",
    "        if(len(stuff)>=5):rest_all_tags[\"delivery_rating\"] = stuff[5]\n",
    "        if(len(stuff)>=7):rest_all_tags[\"delivery_reviews\"] = stuff[7]\n",
    "        if(len(stuff)>=9):rest_all_tags[\"cuisines\"]=[stuff[9]]\n",
    "\n",
    "        for i in range(10,len(stuff)):\n",
    "            if(stuff[i-1]==','):\n",
    "                rest_all_tags[\"cuisines\"].append(stuff[i])\n",
    "\n",
    "        cur = 9+(len(rest_all_tags[\"cuisines\"]*2)-1)\n",
    "        if(len(stuff)>=cur):rest_all_tags[\"location\"] = stuff[cur]\n",
    "\n",
    "        #timings can't be captured in night or off timings!\n",
    "\n",
    "    #         print(len(stuff))\n",
    "    #         print(stuff)\n",
    "\n",
    "    #         print(rest_all_tags)\n",
    "        e = {\n",
    "            'status': 200,\n",
    "            'content':rest_all_tags\n",
    "        }\n",
    "    #         print(e)\n",
    "        return e\n",
    "    except Exception as e:\n",
    "        e = {\n",
    "            'status':997,\n",
    "            'error':str(e)\n",
    "        }\n",
    "        print(e)\n",
    "        print(stuff)\n",
    "        return e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43c8e2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for the rest of the info,\n",
    "just get to the last but one sibling and find text,\n",
    "then find its class then traverse into new one,\n",
    "like cuisines: a,b,c\n",
    "average_cost: a,b,c\n",
    "'''\n",
    "\n",
    "#\n",
    "def get_more_info(content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(content,\"lxml\")\n",
    "        main = soup.find(\"main\").div\n",
    "        \n",
    "        #another way for cuisines:\n",
    "        \n",
    "        # print(stuff.get_text('!@#$%^&').split(\"!@#$%^&\"))\n",
    "        # print(len(stuff.get_text('!@#$%^&').split(\"!@#$%^&\")))\n",
    "\n",
    "        search_elements = ['Cuisines', 'Popular Dishes', '₹','More Info']\n",
    "        # print(stuff)\n",
    "        stuff = main.section\n",
    "        for i in range(4): #iterating through main.section siblings!\n",
    "             stuff = stuff.next_sibling\n",
    "        \n",
    "        stuff = stuff.section.section.article.section.div.next_siblings\n",
    "\n",
    "        cuisines = []\n",
    "        popular_dishes = []\n",
    "        average_costs = []\n",
    "        more_info = []\n",
    "        \n",
    "        for q in stuff:\n",
    "        #     print(q)\n",
    "            if q.text == search_elements[0]:\n",
    "                cuisines = q.next_sibling.get_text(\"!@#$%^&\").split(\"!@#$%^&\")\n",
    "            elif q.text == search_elements[1]:\n",
    "                popular_dishes = q.next_sibling.get_text(\"!@#$%^&\").split(\"!@#$%^&\")\n",
    "            elif search_elements[2] in q.text:\n",
    "                average_costs.append(q.text)\n",
    "            elif q.text == search_elements[3]:\n",
    "                more_info = q.next_sibling.get_text(\"!@#$%^&\").split(\"!@#$%^&\")\n",
    "\n",
    "\n",
    "#         print(cuisines)\n",
    "#         print(popular_dishes)\n",
    "#         print(average_costs)\n",
    "#         print(more_info)\n",
    "\n",
    "        rest_all_tags={'cuisines_2':[],'popular_dishes':[],'average_costs':[],'more_info':[]}\n",
    "        if(cuisines):rest_all_tags['cuisines_2'] = cuisines\n",
    "        if(popular_dishes):rest_all_tags['popular_dishes'] = popular_dishes\n",
    "        if(average_costs):rest_all_tags['average_costs']=average_costs\n",
    "        if(more_info):rest_all_tags['more_info']=more_info\n",
    "#         print(f\"rest all tags:{rest_all_tags}\")\n",
    "        e = {\n",
    "            'status': 200,\n",
    "            'content':rest_all_tags\n",
    "        }\n",
    "#         print(e)\n",
    "        return e\n",
    "    except Exception as e:\n",
    "        e = {\n",
    "            'status': 996,\n",
    "            'content':str(e)\n",
    "        }\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8614907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down(link):\n",
    "    SCROLL_PAUSE_TIME = 3\n",
    "    browser=webdriver.Chrome()\n",
    "#     browser.set_script_timeout(150000) #150 session or browser timeout!\n",
    "    browser.get(link)\n",
    "    while True:\n",
    "        prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         print(prev_height)\n",
    "        ActionChains(browser).send_keys(Keys.END).send_keys(Keys.PAGE_UP).perform()\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         print(new_height)\n",
    "        if new_height == prev_height:\n",
    "            html = browser.page_source\n",
    "            break\n",
    "#     while True:\n",
    "#         prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         print(prev_height)\n",
    "#         browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight/2)\")#height/2 last time\n",
    "#         time.sleep(SCROLL_PAUSE_TIME)\n",
    "#         new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         print(new_height)\n",
    "# #         print(html)\n",
    "#         if new_height == prev_height:\n",
    "#             break\n",
    "#     while True:\n",
    "#         prev_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         print(prev_height)\n",
    "#         browser.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "#         time.sleep(SCROLL_PAUSE_TIME)\n",
    "#         new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         print(new_height)\n",
    "        \n",
    "#         print(html)\n",
    "#         if new_height == prev_height:\n",
    "#             html = browser.page_source\n",
    "#             break\n",
    "    browser.close()\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fbf4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afedfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo = [{\n",
    "#     'aaa':1,\n",
    "#     'bbb':2,\n",
    "#     'ccc':3\n",
    "# }]\n",
    "# demodf = pd.DataFrame(demo)\n",
    "# # demodf.to_excel(\"{}_restaurants_details.xlsx\".format(\"demo\"), index=False)\n",
    "# # demodf.to_excel(\"{}_restaurants_details.xlsx\".format(\"demo\"), index=False)\n",
    "# # print(demodf)\n",
    "# demo2 = [{\n",
    "#     'aaa':4,\n",
    "#     'bbb':5,\n",
    "#     'ccc':6\n",
    "# }]\n",
    "# demo2df = pd.DataFrame(demo2)\n",
    "\n",
    "# print(demodf)\n",
    "\n",
    "\n",
    "# #chat gpt\n",
    "# file_path = \"{}_restaurants_details.xlsx\".format(\"demo3\")\n",
    "# excel_writer = pd.ExcelWriter(file_path, engine='openpyxl',mode='a')\n",
    "# book = load_workbook(file_path)\n",
    "# book = excel_writer.book\n",
    "# sheet_name = book.sheetnames[0]\n",
    "# if sheet_name in book.sheetnames:\n",
    "#     # Load existing sheet\n",
    "#     excel_writer.sheets = {ws.title: ws for ws in book.worksheets}\n",
    "#     print(excel_writer.sheets)\n",
    "# else:\n",
    "#     # Create new sheet\n",
    "# #     demodf = pd.DataFrame()\n",
    "#     demodf.to_excel(excel_writer, index=False, header=False, sheet_name=sheet_name)\n",
    "# # new_dataframe = pd.DataFrame()  # Replace ... with your new data\n",
    "# print(demo2df)\n",
    "# demo2df.to_excel(excel_writer, index=False, header=False, sheet_name=sheet_name, startrow=excel_writer.sheets[sheet_name].max_row)\n",
    "# excel_writer.save()\n",
    "# excel_writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a674629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_into_excel(file_path, data):\n",
    "    \n",
    "#     file_path = \"{}_restaurants_details.xlsx\".format(\"demo\")\n",
    "\n",
    "# Load existing data from the Excel file\n",
    "    existing_data = pd.read_excel(file_path)\n",
    "\n",
    "# Create or retrieve the new dataframe you want to append\n",
    "# new_dataframe = pd.DataFrame(...)  # Replace ... with your new data\n",
    "\n",
    "# Concatenate the existing data and the new dataframe\n",
    "    concatenated_data = pd.concat([existing_data, data], ignore_index=True)\n",
    "\n",
    "# Write the concatenated data to the Excel file\n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter', mode='w') as writer:\n",
    "        concatenated_data.to_excel(writer, index=False, header=True)\n",
    "#     print(\"Data appended successfully.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# demo = [{\n",
    "#     'aaa':1,\n",
    "#     'bbb':2,\n",
    "#     'ccc':3\n",
    "# }]\n",
    "# demodf = pd.DataFrame(demo)\n",
    "# demodf.to_excel(\"{}_restaurants_details.xlsx\".format(\"demo\"), index=False)\n",
    "# demodf.to_excel(\"{}_restaurants_details.xlsx\".format(\"demo\"), index=False)\n",
    "# print(demodf)\n",
    "# demo2 = [{\n",
    "#     'aaa':4,\n",
    "#     'bbb':5,\n",
    "#     'ccc':6\n",
    "# }]\n",
    "# demo2df = pd.DataFrame(demo2)\n",
    "# path = create_excel_file('demo2_file',demo2df.columns)\n",
    "# append_into_excel(path,demodf)\n",
    "# print(demodf)\n",
    "# append_into_excel(path,demo2df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "680c29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel_file(file_name,columns):\n",
    "    data = pd.DataFrame(columns=columns)\n",
    "    now = datetime.now()\n",
    "    file_name = file_name + now.strftime(\"%d.%m.%Y %H-%M-%S \")\n",
    "    file_path = \"restaurant_details/{}-details.xlsx\".format(file_name)\n",
    "    data.to_excel(file_path, index=False)\n",
    "    return file_path\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec673dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "city link: https://www.zomato.com/hyderabad/uppal-restaurants\n",
      "number of restaurants: 72\n",
      "data appended successfully!\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "def scraper():\n",
    "    city_links_hyderabad = ['https://www.zomato.com/hyderabad/jubilee-hills-restaurants','https://www.zomato.com/hyderabad/gachibowli-restaurants','https://www.zomato.com/hyderabad/banjara-hills-restaurants','https://www.zomato.com/hyderabad/hitech-city-restaurants','https://www.zomato.com/hyderabad/madhapur-restaurants','https://www.zomato.com/hyderabad/kondapur-restaurants','https://www.zomato.com/hyderabad/kukatpally-restaurants','https://www.zomato.com/hyderabad/begumpet-restaurants','https://www.zomato.com/hyderabad/himayath-nagar-restaurants','https://www.zomato.com/hyderabad/tolichowki-restaurants','https://www.zomato.com/hyderabad/ameerpet-restaurants','https://www.zomato.com/hyderabad/somajiguda-restaurants','https://www.zomato.com/hyderabad/film-nagar-restaurants','https://www.zomato.com/hyderabad/paradise-circle-restaurants','https://www.zomato.com/hyderabad/sainikpuri-restaurants','https://www.zomato.com/hyderabad/necklace-road-restaurants','https://www.zomato.com/hyderabad/kothapet-restaurants','https://www.zomato.com/hyderabad/sd-road-restaurants','https://www.zomato.com/hyderabad/abids-restaurants','https://www.zomato.com/hyderabad/kompally-restaurants','https://www.zomato.com/hyderabad/masab-tank-restaurants','https://www.zomato.com/hyderabad/gandipet-restaurants','https://www.zomato.com/hyderabad/lb-nagar-restaurants','https://www.zomato.com/hyderabad/miyapur-restaurants','https://www.zomato.com/hyderabad/karkhana-restaurants','https://www.zomato.com/hyderabad/basheer-bagh-restaurants','https://www.zomato.com/hyderabad/panjagutta-restaurants','https://www.zomato.com/hyderabad/as-rao-nagar-restaurants','https://www.zomato.com/hyderabad/uppal-restaurants']\n",
    "#     city_links_hyderabad.reverse()\n",
    "#     city_links_hyderabad = [city_links_hyderabad[-1]];\n",
    "    city_names = []\n",
    "    for city_link in city_links_hyderabad:\n",
    "#             link = \"https://www.zomato.com/hyderabad/{}-restaurants\".format(city_name)\n",
    "#         link = \"https://www.zomato.com/hyderabad/jubilee-hills-restaurants\"\n",
    "#         print(city_link)\n",
    "        html = scroll_down(city_link)\n",
    "#         print(\"html is working?\")\n",
    "        r = get_restaurant_links_via_html(html)\n",
    "#         print(\"number of search_list:\"+str(len(search_list)))\n",
    "#         r = get_restaurant_links_via_href(\"hyderabad\")\n",
    "#         print(\"r value!\")\n",
    "        restaurant_links=[]\n",
    "        if(r['status']!=200):\n",
    "            html = scroll_down(link)\n",
    "            r=get_restaurant_links_via_html(html)\n",
    "        else:\n",
    "            restaurant_links = r['content']\n",
    "\n",
    "        columns = ['country','city','city_2','region','restaurant_name','restaurant_name_2','dining_rating', 'dining_reviews', 'delivery_rating', 'delivery_reviews','cuisines','location', 'cuisines_2', 'popular_dishes','average_costs','more_info']\n",
    "\n",
    "        #creating an excel file to append into this later\n",
    "        file_path = create_excel_file(city_link.split('/')[-1],columns)\n",
    "        city_names.append(city_link.split('/')[-1])\n",
    "\n",
    "        for link in restaurant_links:\n",
    "            details={}\n",
    "            page = get_page_content(link, headers)\n",
    "    #         if(page['status'] != 200):\n",
    "    #             continue\n",
    "            page = page['content']\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "\n",
    "            data = get_primary_data(page)\n",
    "            if(data['status']==200):\n",
    "                details.update(data['content'])\n",
    "            else:\n",
    "                details.update({'country':'','city':'','city_2':'','region':'','restaurant_name':''})\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "\n",
    "\n",
    "            data = get_secondary_data(page)\n",
    "            if(data['status']==200):\n",
    "                details.update(data['content'])\n",
    "            else:\n",
    "                details.update({'restaurant_name_2':'','dining_rating':0.0,'dining_reviews':0,'delivery_rating':0.0,'delivery_reviews':0,'cuisines':[],'location':''})\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "\n",
    "            data = get_more_info(page)\n",
    "            if(data['status']==200):\n",
    "                details.update(data['content'])\n",
    "            else:\n",
    "                details.update({'cuisines_2':[],'popular_dishes':[],'average_costs':[],'more_info':[]})\n",
    "\n",
    "            # appending restaurant details\n",
    "#             print(details)\n",
    "#             print(columns)\n",
    "            details = [details]\n",
    "            details_df=pd.DataFrame(details,columns=columns)\n",
    "#             details_df = pd.DataFrame.from_dict(details, orient='columns',columns=columns)\n",
    "#             details_df.transpose()\n",
    "#             print(details_df)\n",
    "\n",
    "            append_into_excel(file_path,details_df)\n",
    "\n",
    "\n",
    "#                 df = pd.DataFrame(technologies)\n",
    "#                 new_row = {'Courses':'Hyperion', 'Fee':24000, 'Duration':'55days', 'Discount':1800}\n",
    "#                 df2 = df.append(new_row, ignore_index=True)\n",
    "\n",
    "#                 all_restaurant_details = all_restaurant_details.append(details, ignore_index=True)\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "        \n",
    "        print(\"#\"*20)\n",
    "        print(f\"city link: {city_link}\")\n",
    "        print(f\"number of restaurants: {len(restaurant_links)}\")\n",
    "        print(\"data appended successfully!\")\n",
    "        print(\"#\"*20)\n",
    "\n",
    "\n",
    "#         df = pd.DataFrame(all_restaurant_details)\n",
    "#         print(df)\n",
    "#         print(all_restaurant_details)\n",
    "#             print(\"all_restaurants_details: {}\".format(len(all_restaurant_details)))\n",
    "\n",
    "        #to excel file\n",
    "#         all_restaurant_details.to_excel(\"{}_restaurants_details.xlsx\".format(\"jubilee_hills\"), index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f2338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_names=[]\n",
    "# for city_link in city_links_hyderabad:\n",
    "#     city_names.append(city_link.split('/')[-1])\n",
    "# main_file = \"hyderabad-compiled-restaurants-details.xlsx\"\n",
    "# create_excel_file(main_file,columns)\n",
    "\n",
    "# main_excel_df = pd.read_excel(main_file)\n",
    "# with pd.ExcelWriter(file_path, engine='xlsxwriter', mode='w') as writer:\n",
    "#     concatenated_data.to_excel(writer, index=False, header=True)\n",
    "# print(\"Data appended successfully.\")\n",
    "# print(city_names)\n",
    "# file_name = \"\"\n",
    "# now = datetime.now()\n",
    "# file_name = file_name + now.strftime(\"%d.%m.%Y %H-%M-%S\")\n",
    "# print(type(file_name))\n",
    "# print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b614da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this_link = \"https://www.zomato.com/hyderabad/ram-ki-bandi-gachibowli\"\n",
    "# random_html = get_page_content(this_link,headers)\n",
    "# get_secondary_data(random_html['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f8e84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
