{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a03f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using snake casing to name variables and functions\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd40334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "city_name = \"hyderabad\"\n",
    "zomato_url = \"https://www.zomato.com\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0304bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(link,headers):\n",
    "    try:\n",
    "        #link = 'https://www.zomato.com/hyderabad/antera-kitchen-and-bar-jubilee-hills'\n",
    "        response = requests.get(link, headers=headers)\n",
    "        #response = requests.get(\"https://www.zomato.com/hyderabad/papadams-blue-kothapet/order\")\n",
    "        return {'status':response.status_code,\n",
    "                'content': response.content}\n",
    "    \n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"Http Error:\"+errh}\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"Error Connecting:\"+errc}\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"Timeout Error:\"+errt}\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        return {'status':response.status_code,\n",
    "                'content':\"OOps: Something Else\"+err}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e9e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_links(city_name):\n",
    "    try:\n",
    "        url = \"https://www.zomato.com/{}/restaurants\".format(city_name)\n",
    "        print(url)\n",
    "        response = get_page_content(url,headers)\n",
    "#         print(type(response))\n",
    "        if(response['status']==200):\n",
    "            content = response['content']\n",
    "            soup = BeautifulSoup(content,\"lxml\")\n",
    "            search_list = soup.find_all(\"div\", {\"class\":\"jumbo-tracker\"})\n",
    "            print(\"number of search_list:\"+str(len(search_list)))\n",
    "\n",
    "            restaurant_links=[]\n",
    "            ################################ \n",
    "            #need to edit here, indices starts from 22 to len() ??? we need all!\n",
    "            ################################ \n",
    "            for i in range(22,len(search_list)):\n",
    "                link = search_list[i].div.find('a')['href']\n",
    "                link = link.replace('/order', '')\n",
    "                print(link)\n",
    "                restaurant_links.append(zomato_url+link)\n",
    "\n",
    "            print(\"total number of restaurant links:\" + str(len(restaurant_links)))\n",
    "            \n",
    "            #     for x in (details[0].find_all(True)):\n",
    "            #         if(x.string!=None):\n",
    "            #             print(x.string+' {}'.format(i))\n",
    "            #             i+=1\n",
    "            e = {\n",
    "                'status':200,\n",
    "                'content':restaurant_links\n",
    "            }\n",
    "#             print(e)\n",
    "            return e\n",
    "    except Exception as e:\n",
    "        e = {\"status\":999,'error':str(e)}\n",
    "        print(e)\n",
    "        return e\n",
    "\n",
    "# print(get_restaurant_links(city_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b2094cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #just learnt abt beautiful-soup-4!\n",
    "\n",
    "# jumbo_tracker = soup.select('.jumbo-tracker')\n",
    "# tag = jumbo_tracker[0]\n",
    "# #print tag-name\n",
    "# print(tag.name) # yes its a div tag!\n",
    "# #u can edit tag name in the current soup too!\n",
    "# print(tag.attrs)\n",
    "# print(tag.get('class'))\n",
    "# print(type(soup))\n",
    "# print(len(soup.find_all(attrs={'class':'jumbo-tracker'})))\n",
    "# print(len(soup.find_all('div',attrs={'class':'jumbo-tracker'})))\n",
    "# print(len(soup.select('div[class=\"jumbo-tracker\"]')))\n",
    "# print(soup.select('div[class=\"jumbo-tracker\"]')[-1])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aad1db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86d0a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns get restaurant page content for 200 successful response\n",
    "\n",
    "def get_primary_data(content):\n",
    "    try:\n",
    "        \n",
    "        soup = BeautifulSoup(content,\"lxml\")\n",
    "\n",
    "        main = soup.find(\"main\").div\n",
    "\n",
    "        # location = soup.find(\"div\",{\"aria-label\":\"Breadcrumb\"}).find_all(\"a\")\n",
    "        location = main.section.div.find_all(\"a\")\n",
    "#         print(location)\n",
    "\n",
    "        loc_tags = [tag[\"title\"] for tag in location]\n",
    "\n",
    "        rest_all_tags = {\n",
    "            \"country\":loc_tags[1],\n",
    "            \"city\":loc_tags[2],\n",
    "            \"city_2\":loc_tags[3],\n",
    "            \"region\":loc_tags[4],\n",
    "            \"restaurant_name\":loc_tags[5],\n",
    "        }\n",
    "#         print(len(loc_tags))\n",
    "#         print(loc_tags)\n",
    "    #rest_all_tags[\"order_online\"] = True if(loc_tags[6]=='Order Online') else False\n",
    "    # order_online is invalid in off timings\n",
    "\n",
    "    # loc_tags = loc_tags[1:len(loc_tags)-1]\n",
    "\n",
    "#         print(rest_all_tags)\n",
    "        \n",
    "        e = {\n",
    "            'status': 200,\n",
    "            'content': rest_all_tags\n",
    "        }\n",
    "#         print(e)\n",
    "        return e\n",
    "    \n",
    "    except Exception as e:\n",
    "        e =  {\n",
    "            'status': 998,\n",
    "            'error': str(e)\n",
    "        }\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ab0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_secondary_data(content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(content,\"lxml\")\n",
    "        main = soup.find(\"main\").div\n",
    "        \n",
    "        stuff = main.section.next_sibling.next_sibling.section\n",
    "        stuff = stuff.get_text(\"!@#$%^&\",strip=True).split(\"!@#$%^&\")\n",
    "#         print(stuff)\n",
    "        \n",
    "        rest_all_tags={}\n",
    "        rest_all_tags[\"restaurant_name_2\"] = stuff[0]\n",
    "        rest_all_tags[\"dining_rating\"] = stuff[1]\n",
    "        rest_all_tags[\"dining_reviews\"] = stuff[3]\n",
    "        rest_all_tags[\"delivery_rating\"] = stuff[5]\n",
    "        rest_all_tags[\"delivery_reviews\"] = stuff[7]\n",
    "        rest_all_tags[\"cuisines\"]=[stuff[9]]\n",
    "\n",
    "        for i in range(9,len(stuff)):\n",
    "            if(stuff[i-1]==','):\n",
    "                rest_all_tags[\"cuisines\"].append(stuff[i])\n",
    "\n",
    "        cur = 9+(len(rest_all_tags[\"cuisines\"]*2)-1)\n",
    "        rest_all_tags[\"location\"] = stuff[cur]\n",
    "\n",
    "        #timings can't be captured in night or off timings!\n",
    "\n",
    "#         print(len(stuff))\n",
    "#         print(stuff)\n",
    "        \n",
    "#         print(rest_all_tags)\n",
    "        e = {\n",
    "            'status': 200,\n",
    "            'content':rest_all_tags\n",
    "        }\n",
    "#         print(e)\n",
    "        return e\n",
    "    except Exception as e:\n",
    "        e = {\n",
    "            'status':997,\n",
    "            'error':str(e)\n",
    "        }\n",
    "        print(e)\n",
    "        return e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43c8e2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for the rest of the info,\n",
    "just get to the last but one sibling and find text,\n",
    "then find its class then traverse into new one,\n",
    "like cuisines: a,b,c\n",
    "average_cost: a,b,c\n",
    "'''\n",
    "\n",
    "#\n",
    "def get_more_info(content):\n",
    "    try:\n",
    "        soup = BeautifulSoup(content,\"lxml\")\n",
    "        main = soup.find(\"main\").div\n",
    "        \n",
    "        #another way for cuisines:\n",
    "        \n",
    "        # print(stuff.get_text('!@#$%^&').split(\"!@#$%^&\"))\n",
    "        # print(len(stuff.get_text('!@#$%^&').split(\"!@#$%^&\")))\n",
    "\n",
    "        search_elements = ['Cuisines', 'Popular Dishes', 'â‚¹','More Info']\n",
    "        # print(stuff)\n",
    "        stuff = main.section\n",
    "        for i in range(4): #iterating through main.section siblings!\n",
    "             stuff = stuff.next_sibling\n",
    "        \n",
    "        stuff = stuff.section.section.article.section.div.next_siblings\n",
    "\n",
    "        cuisines = []\n",
    "        popular_dishes = []\n",
    "        average_costs = []\n",
    "        more_info = []\n",
    "        \n",
    "        for q in stuff:\n",
    "        #     print(q)\n",
    "            if q.text == search_elements[0]:\n",
    "                cuisines = q.next_sibling.get_text(\"!@#$%^&\").split(\"!@#$%^&\")\n",
    "            elif q.text == search_elements[1]:\n",
    "                popular_dishes = q.next_sibling.get_text(\"!@#$%^&\").split(\"!@#$%^&\")\n",
    "            elif search_elements[2] in q.text:\n",
    "                average_costs.append(q.text)\n",
    "            elif q.text == search_elements[3]:\n",
    "                more_info = q.next_sibling.get_text(\"!@#$%^&\").split(\"!@#$%^&\")\n",
    "\n",
    "\n",
    "#         print(cuisines)\n",
    "#         print(popular_dishes)\n",
    "#         print(average_costs)\n",
    "#         print(more_info)\n",
    "\n",
    "        rest_all_tags={}\n",
    "        rest_all_tags['cuisines_2'] = cuisines\n",
    "        rest_all_tags['popular_dishes'] = popular_dishes\n",
    "        rest_all_tags['average_costs']=average_costs\n",
    "        rest_all_tags['more_info']=more_info\n",
    "#         print(f\"rest all tags:{rest_all_tags}\")\n",
    "        e = {\n",
    "            'status': 200,\n",
    "            'content':rest_all_tags\n",
    "        }\n",
    "#         print(e)\n",
    "        return e\n",
    "    except Exception as e:\n",
    "        e = {\n",
    "            'status': 996,\n",
    "            'content':str(e)\n",
    "        }\n",
    "        print(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8614907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.json_normalize(rest_all_tags) \n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baebc9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.zomato.com/hyderabad/restaurants\n",
      "number of search_list:31\n",
      "/hyderabad/santosh-dhaba-2-begum-bazaar\n",
      "/hyderabad/mithaiwala-kothapet\n",
      "/hyderabad/spice-9-restaurant-malakpet\n",
      "/hyderabad/4m-biryani-house-musheerabad\n",
      "/hyderabad/hotel-nayaab-charminar\n",
      "/hyderabad/balaji-santosh-family-dhaba-amberpet\n",
      "/hyderabad/peshawar-2-malakpet\n",
      "/hyderabad/papaji-da-dhaba-1-amberpet\n",
      "/hyderabad/nimrah-restaurant-nampally\n",
      "total number of restaurant links:9\n",
      "  country       city          city_2        region  \\\n",
      "0   India  Hyderabad  Hyderabad City  Begum Bazaar   \n",
      "1   India  Hyderabad  Hyderabad City      Kothapet   \n",
      "2   India  Hyderabad  Hyderabad City      Malakpet   \n",
      "3   India  Hyderabad  Hyderabad City   Musheerabad   \n",
      "4   India  Hyderabad  Hyderabad City     Charminar   \n",
      "5   India  Hyderabad  Hyderabad City      Amberpet   \n",
      "6   India  Hyderabad  Hyderabad City      Malakpet   \n",
      "7   India  Hyderabad  Hyderabad City      Amberpet   \n",
      "8   India  Hyderabad  Hyderabad City      Nampally   \n",
      "\n",
      "               restaurant_name            restaurant_name_2 dining_rating  \\\n",
      "0                Santosh Dhaba                Santosh Dhaba           3.5   \n",
      "1                   Mithaiwala                   Mithaiwala           4.2   \n",
      "2           Spice 9 Restaurant           Spice 9 Restaurant           3.6   \n",
      "3             4M Biryani House             4M Biryani House           4.1   \n",
      "4                 Hotel Nayaab                 Hotel Nayaab           4.4   \n",
      "5  Balaji Santosh Family Dhaba  Balaji Santosh Family Dhaba           3.8   \n",
      "6                     Peshawar                     Peshawar             -   \n",
      "7              Papaji-Da-Dhaba              Papaji-Da-Dhaba             -   \n",
      "8            Nimrah Restaurant            Nimrah Restaurant           3.9   \n",
      "\n",
      "  dining_reviews delivery_rating delivery_reviews  \\\n",
      "0            181             3.5              15K   \n",
      "1            510             4.0               53   \n",
      "2             30             3.9            4,350   \n",
      "3          3,757             4.2           231.6K   \n",
      "4            538             3.9            4,950   \n",
      "5            273             4.2            17.8K   \n",
      "6              3             4.2              230   \n",
      "7              0             4.1            16.7K   \n",
      "8             71             4.0              402   \n",
      "\n",
      "                                            cuisines                 location  \\\n",
      "0  [North Indian, Chinese, Biryani, Sichuan, Sand...  Begum Bazaar, Hyderabad   \n",
      "1                      [Mithai, Bakery, Street Food]      Kothapet, Hyderabad   \n",
      "2  [Hyderabadi, North Indian, Chinese, Mughlai, K...      Malakpet, Hyderabad   \n",
      "3       [Biryani, Hyderabadi, North Indian, Chinese]   Musheerabad, Hyderabad   \n",
      "4        [North Indian, Mughlai, Chinese, Beverages]     Charminar, Hyderabad   \n",
      "5      [Chinese, North Indian, Ice Cream, Beverages]      Amberpet, Hyderabad   \n",
      "6            [North Indian, Seafood, Kebab, Chinese]      Malakpet, Hyderabad   \n",
      "7          [North Indian, Mughlai, Chinese, Biryani]      Amberpet, Hyderabad   \n",
      "8                                [Bakery, Fast Food]      Nampally, Hyderabad   \n",
      "\n",
      "                                          cuisines_2  \\\n",
      "0  [North Indian, Chinese, Biryani, Sichuan, Sand...   \n",
      "1                      [Mithai, Bakery, Street Food]   \n",
      "2  [Hyderabadi, North Indian, Chinese, Mughlai, K...   \n",
      "3       [Biryani, Hyderabadi, North Indian, Chinese]   \n",
      "4        [North Indian, Mughlai, Chinese, Beverages]   \n",
      "5      [Chinese, North Indian, Ice Cream, Beverages]   \n",
      "6            [North Indian, Seafood, Kebab, Chinese]   \n",
      "7          [North Indian, Mughlai, Chinese, Biryani]   \n",
      "8                                [Bakery, Fast Food]   \n",
      "\n",
      "                                      popular_dishes  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2                                                 []   \n",
      "3  [Beef Masala, Mirch Ka Saalan, Tandoori Chicke...   \n",
      "4  [Paya, Khichdi, Keema, Butter Naan, Haleem, Roti]   \n",
      "5                                                 []   \n",
      "6                                                 []   \n",
      "7                                                 []   \n",
      "8                                                 []   \n",
      "\n",
      "                       average_costs  \\\n",
      "0    [â‚¹650 for two people (approx.)]   \n",
      "1    [â‚¹300 for two people (approx.)]   \n",
      "2    [â‚¹950 for two people (approx.)]   \n",
      "3    [â‚¹300 for two people (approx.)]   \n",
      "4    [â‚¹850 for two people (approx.)]   \n",
      "5    [â‚¹700 for two people (approx.)]   \n",
      "6  [â‚¹1,200 for two people (approx.)]   \n",
      "7     [â‚¹150 for one order (approx.)]   \n",
      "8    [â‚¹200 for two people (approx.)]   \n",
      "\n",
      "                                           more_info  \n",
      "0  [Home Delivery, Takeaway Available, Vegetarian...  \n",
      "1  [Breakfast, Home Delivery, Takeaway Available,...  \n",
      "2  [Home Delivery, Takeaway Available, Indoor Sea...  \n",
      "3  [Home Delivery, Takeaway Available, Indoor Sea...  \n",
      "4  [Breakfast, Home Delivery, Takeaway Available,...  \n",
      "5  [Home Delivery, Takeaway Available, Vegetarian...  \n",
      "6  [Home Delivery, Takeaway Available, Family Fri...  \n",
      "7  [Home Delivery, Takeaway Available, No Seating...  \n",
      "8  [Breakfast, Home Delivery, Takeaway Available,...  \n",
      "9\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        r = get_restaurant_links(city_name)\n",
    "        restaurant_links=[]\n",
    "        if(r['status']!=200):\n",
    "            r=get_restaurant_links(city_name)\n",
    "        else:\n",
    "            restaurant_links = r['content']\n",
    "        \n",
    "        columns = ['country','city','city_2','region','restaurant_name',\n",
    "                   'restaurant_name_2','dining_rating', \n",
    "                   'dining_reviews', 'delivery_rating', 'delivery_reviews',\n",
    "                   'cuisines','location', 'cuisines_2', 'popular_dishes',\n",
    "                   'average_costs','more_info'\n",
    "                  ]\n",
    "        all_restaurant_details = pd.DataFrame(columns = columns)\n",
    "        \n",
    "        for link in restaurant_links:\n",
    "            details={}\n",
    "            page = get_page_content(link, headers)\n",
    "    #         if(page['status'] != 200):\n",
    "    #             continue\n",
    "            page = page['content']\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "\n",
    "            data = get_primary_data(page)\n",
    "            if(data['status']==200):\n",
    "                details.update(data['content'])\n",
    "            else:\n",
    "                details.update({\n",
    "                      'country': '',\n",
    "                      'city': '',\n",
    "                      'city_2': '',\n",
    "                      'region': '',\n",
    "                      'restaurant_name': ''\n",
    "                })\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "\n",
    "\n",
    "            data = get_secondary_data(page)\n",
    "            if(data['status']==200):\n",
    "                details.update(data['content'])\n",
    "            else:\n",
    "                details.update({\n",
    "                      'restaurant_name_2': '',\n",
    "                      'dining_rating': 0.0,\n",
    "                      'dining_reviews': 0,\n",
    "                      'delivery_rating': 0.0,\n",
    "                      'delivery_reviews': 0,\n",
    "                      'cuisines': [],\n",
    "                      'location': ''\n",
    "                    })\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "\n",
    "            data = get_more_info(page)\n",
    "            if(data['status']==200):\n",
    "                details.update(data['content'])\n",
    "            else:\n",
    "                details.update({\n",
    "                      'cuisines_2': [],\n",
    "                      'popular_dishes': [],\n",
    "                      'average_costs': [],\n",
    "                      'more_info': []\n",
    "                    })\n",
    "                \n",
    "                df = pd.DataFrame(technologies)\n",
    "                new_row = {'Courses':'Hyperion', 'Fee':24000, 'Duration':'55days', 'Discount':1800}\n",
    "                df2 = df.append(new_row, ignore_index=True)\n",
    "                \n",
    "                \n",
    "            all_restaurant_details.append(details)\n",
    "    #         print(link)\n",
    "    #         print(details)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        df = pd.DataFrame(all_restaurant_details)\n",
    "        print(df)\n",
    "        print(len(all_restaurant_details))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error: \"+str(e))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317998b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa54df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
